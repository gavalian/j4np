\section{Motivation}
\label{section-motivation}

%Data stored from physics experiments consists of "events" that record information from a setup for one interaction of the incident beam particle
%with the target. These "events" are processed independently to identify particles and tracks identified by different detector components and construct a physics event, which is then used for high-level physics analysis. The information stored in one "event" is a collection of responses from all detector components with unique data structures. The data collected during the experiment undergoes several transformations before it reaches the stage where it is used for physics analysis.

Physics experiment data consists of "events," each representing information captured from a single interaction between an incident beam particle and the target. These events are processed individually to identify particles and reconstruct tracks using data from various detector components. This process builds a complete physics event, which serves as the foundation for high-level physics analysis. Each event encapsulates a collection of responses from all detector components, organized in unique data structures. Before reaching the stage of physics analysis, the collected data undergoes multiple transformations to prepare and refine it for further study.

\begin{itemize}
\item The data acquisition records data from all detector components for one instance of interaction in raw format  (usually times and accumulated charge in each component of each detector system) 
\item In the next stage, the raw data is transformed from its digital form to values with units, such as time in milliseconds and energy in eV.
\item The reconstruction program analyses data from each detector to identify related signals and combines signals from various detectors to identify particles in each event (collision instance). The produced output contains tables with information about the particles in the event and the responses of each particle in each detector component, helping to identify particle species.
\item For each physics analysis, different sets of selection algorithms are used to identify the physics reaction in each event and physics observables are calculated based on detected particles in the event, and the output is produced containing a columnar table for final physics analysis. 
\end{itemize}

In traditional CLAS~\cite{CLAS:2003umf} experiments, different data formats were used at each stage of the data lifecycle, leading to unnecessary complexity. This required supporting multiple file formats and maintaining numerous conversion tools. Additionally, users developed dozens of data selection and filtering tools tailored to specific formats, all of which required ongoing maintenance. Initially, a similar approach was considered for the CLAS12~\cite{Burkert:2020akg} experiment during its early software development stages.

However, experienced developers quickly recognized the challenges of this approach and envisioned a more streamlined solution. To address these issues, it was decided to adopt a single data format for all stages of the experimental data lifecycle. Several existing formats, such as ROOT~\cite{Brun:1997pa}, LCIO~\cite{Aplin:2012kj}, and HDF5~\cite{HDF5:2000pa}, were evaluated. While each had its strengths, none were found to efficiently support all stages of data transformation. Furthermore, the growing diversity of data analysis frameworks and programming languages introduced additional challenges, as seamless integration required appropriate language bindingsâ€”complicating the use of existing formats in unified workflows.

To overcome these limitations, the High-Performance Output (HiPO)~\cite{hipo5p0:2025jk} data format was developed specifically for CLAS12. HiPO is designed to efficiently handle all stages of experimental data processing, from reconstruction workflows to final columnar data analysis. It also provides language bindings for a variety of programming languages used within the collaboration, including C++, FORTRAN, Python, Java, and Julia, ensuring broad compatibility and streamlined workflows.


To ensure usability across all workflows of data processing, several key requirements were established for the data format:

%Several requirements were imposed to ensure usability in all workflows of data processing, as follows:
\begin{itemize}
\item {\bf Serializable:} The CLAS12 reconstruction workflow follows a Service-Oriented Architecture (SOA) that operates on a heterogeneous platform using message passing. The data format was designed to be easily serializable, enabling efficient transmission of event data to individual reconstruction services.
\item {\bf Compression Efficiency:} To minimize storage demands, the data format incorporates compression. The compression algorithm must balance speed and compression ratio, as high compression speed is critical for managing the large data volumes produced by experimental setups, particularly in high-rate nuclear physics experiments where maintaining high data throughput is essential.
\item {\bf Random Access Capability:} The format must support random access to specific data collections within a file. This functionality is vital for debugging, selectively writing subsets of data, and supporting multi-threaded applications that process data chunks asynchronously.
\item {\bf Data Grouping Functionality:} The format should enable the grouping of related datasets, allowing for efficient tagging or marking of different datasets. This capability facilitates the targeted reading of specific groups without requiring the processing of the entire dataset.
\end{itemize}

The reconstruction of experimental data in CLAS12 is written in Java, for this reason, Java is the primary development platform of the HiPO library, and the C++ library is developed in parallel, sometimes lagging in features, but they are being slowly ported to the C++ code. Most of the example codes in this article are Java, the equivalent C++ examples can be found in the repository.
There are experimental bindings to Python and Julia, which are not actively developed due to limited use by collaborators.
The subsequent chapters will explore the features of the HiPO data format in greater detail, with illustrative examples.
